{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "nlp=spacy.load('ru_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('banks.csv',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenizer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>1 июня 2016 года с моей дебетовой карты мошенн...</td>\n",
       "      <td>[1, июня, 2016, года, дебетовой, карты, мошенн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>После переноса остатков по счетам Бинбанк Стол...</td>\n",
       "      <td>[переноса, остатков, счетам, Бинбанк, Столица,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11327</th>\n",
       "      <td>Часто просматриваю в интернете предложения раз...</td>\n",
       "      <td>[просматриваю, интернете, предложения, разных,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13973</th>\n",
       "      <td>Случилась у меня ситуация, - продал квартиру, ...</td>\n",
       "      <td>[Случилась, ситуация, продал, квартиру, положи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Добрый день! Хочу выразить благодарность менед...</td>\n",
       "      <td>[Добрый, день, выразить, благодарность, менедж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>Неделю назад при открытии вклада (открывал с ц...</td>\n",
       "      <td>[Неделю, открытии, вклада, открывал, целью, фи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13418</th>\n",
       "      <td>Несмотря на глобальные издевательства Сбербанк...</td>\n",
       "      <td>[Несмотря, глобальные, издевательства, Сбербан...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>7 февраля 2011 года моя жена, Федотова Оксана ...</td>\n",
       "      <td>[7, февраля, 2011, года, жена, Федотова, Оксан...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Хочу написать об отвратительной работе связки ...</td>\n",
       "      <td>[написать, отвратительной, работе, связки, Аль...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>Здравствуйте! В 2016 году, решил завести себе ...</td>\n",
       "      <td>[Здравствуйте, 2016, году, решил, завести, деб...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "9866   1 июня 2016 года с моей дебетовой карты мошенн...   \n",
       "365    После переноса остатков по счетам Бинбанк Стол...   \n",
       "11327  Часто просматриваю в интернете предложения раз...   \n",
       "13973  Случилась у меня ситуация, - продал квартиру, ...   \n",
       "147    Добрый день! Хочу выразить благодарность менед...   \n",
       "...                                                  ...   \n",
       "5191   Неделю назад при открытии вклада (открывал с ц...   \n",
       "13418  Несмотря на глобальные издевательства Сбербанк...   \n",
       "5390   7 февраля 2011 года моя жена, Федотова Оксана ...   \n",
       "860    Хочу написать об отвратительной работе связки ...   \n",
       "7270   Здравствуйте! В 2016 году, решил завести себе ...   \n",
       "\n",
       "                                          tokenizer_text  \n",
       "9866   [1, июня, 2016, года, дебетовой, карты, мошенн...  \n",
       "365    [переноса, остатков, счетам, Бинбанк, Столица,...  \n",
       "11327  [просматриваю, интернете, предложения, разных,...  \n",
       "13973  [Случилась, ситуация, продал, квартиру, положи...  \n",
       "147    [Добрый, день, выразить, благодарность, менедж...  \n",
       "...                                                  ...  \n",
       "5191   [Неделю, открытии, вклада, открывал, целью, фи...  \n",
       "13418  [Несмотря, глобальные, издевательства, Сбербан...  \n",
       "5390   [7, февраля, 2011, года, жена, Федотова, Оксан...  \n",
       "860    [написать, отвратительной, работе, связки, Аль...  \n",
       "7270   [Здравствуйте, 2016, году, решил, завести, деб...  \n",
       "\n",
       "[2799 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Score'], test_size=0.8, random_state=42)\n",
    "nlp = spacy.load('ru_core_news_sm')\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for text in tqdm(X_train):\n",
    "    doc = nlp(text)\n",
    "    token = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    tokens.append(token)\n",
    "    \n",
    "\n",
    "df2 = pd.DataFrame({'text': X_train, 'tokenizer_text': tokens})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "data['Score'] = encoder.fit_transform(data['Score'])\n",
    "data['Score'] = data['Score'].map(lambda x: 1 if x=='Positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('banks.csv',sep=\"\\t\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'],data['Score'], test_size=0.2, random_state=40)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=8000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.map(lambda x: 1 if x=='Positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "88/88 [==============================] - 1s 1ms/step - loss: 0.5088 - accuracy: 0.8494\n",
      "Epoch 2/5\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.9213\n",
      "Epoch 3/5\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.9366\n",
      "Epoch 4/5\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.1622 - accuracy: 0.9448\n",
      "Epoch 5/5\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9482\n",
      "88/88 [==============================] - 0s 920us/step - loss: 0.1798 - accuracy: 0.9332\n",
      "Loss: 0.17976771295070648, Accuracy: 0.9332143068313599\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "data = pd.read_csv('banks.csv',sep=\"\\t\")\n",
    "\n",
    "data['Score'] = data['Score'].map(lambda x: 1 if x=='Positive' else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Score'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1024)  \n",
    "X_train_tfidf = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(32*32,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "\n",
    "model.fit(X_train_tfidf, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_tfidf, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
